{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#!pip install dataloader\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\r\n",
      "Version: 1.11.0\r\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\r\n",
      "Home-page: https://pytorch.org/\r\n",
      "Author: PyTorch Team\r\n",
      "Author-email: packages@pytorch.org\r\n",
      "License: BSD-3\r\n",
      "Location: /opt/conda/lib/python3.7/site-packages\r\n",
      "Requires: typing-extensions\r\n",
      "Required-by: torchvision, torchtext\r\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu102'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch;\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eg81uNTWixbi",
    "outputId": "9c0f9eda-75fb-4526-e9b6-f9a76eeeb007"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import torch\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pandas.io.json import json_normalize \n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Output, save, and load brown embeddings\n",
    "\n",
    "model = gensim.models.Word2Vec(brown.sents())\n",
    "model.save('brown.embedding')\n",
    "\n",
    "w2v = gensim.models.Word2Vec.load('brown.embedding')\n",
    "\n",
    "def clean_text(x):\n",
    "    if len(x) > 0:\n",
    "        return x[0][\"text\"]\n",
    "\n",
    "def loadDF(path):\n",
    "    \n",
    "    df = pd.read_json(path) \n",
    "    data = pd.json_normalize(data = df['data'],\n",
    "                            record_path =['paragraphs', 'qas'])\n",
    "    data = data.drop('id', axis=1)\n",
    "    data = data.drop('is_impossible', axis=1)\n",
    "    data = data.drop('plausible_answers', axis=1)\n",
    "    data['answers'] = data['answers'].apply(clean_text)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def tokenize_en(text):\n",
    "    if text != None:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        return [tok.lower().strip() for tok in word_tokenize(text)]\n",
    "    return;\n",
    "\n",
    "#, dev_test\n",
    "def prepare_text(df_train):\n",
    "    \n",
    "    for i,r, in df_train.iterrows():\n",
    "        answerlist = r['answers']\n",
    "        if answerlist != None:\n",
    "            answerlist = [i for i in answerlist if i]\n",
    "            if len(answerlist) == 0:\n",
    "                r['answers'] =  np.NaN\n",
    "                     \n",
    "    df_train = df_train.dropna(axis=0, subset=['answers'])\n",
    "    df_train.reset_index(drop=True)\n",
    "   \n",
    "    \n",
    "    df_train['question_token'] = df_train['question'].apply(tokenize_en)\n",
    "    df_train['answer_token'] = df_train['answers'].apply(tokenize_en) \n",
    "    \n",
    "    #dev_test['question_token'] = dev_test['question'].apply(tokenize_en)\n",
    "    #dev_test['answer_token'] = dev_test['answers'].apply(tokenize_en) \n",
    "    \n",
    "    return df_train #, dev_test\n",
    "\n",
    "\n",
    "\n",
    "def train_test_split(SRC, TRG):\n",
    "    \n",
    "    '''\n",
    "    Input: SRC, our list of questions from the dataset\n",
    "            TRG, our list of responses from the dataset\n",
    "\n",
    "    Output: Training and test datasets for SRC & TRG\n",
    "\n",
    "    '''\n",
    "    \n",
    "    return SRC_train_dataset, SRC_test_dataset, TRG_train_dataset, TRG_test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = loadDF('./train-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_test = loadDF('./dev-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question              answers\n",
       "0           When did Beyonce start becoming popular?    in the late 1990s\n",
       "1  What areas did Beyonce compete in when she was...  singing and dancing\n",
       "2  When did Beyonce leave Destiny's Child and bec...                 2003\n",
       "3      In what city and state did Beyonce  grow up?        Houston, Texas\n",
       "4         In which decade did Beyonce become famous?           late 1990s"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_train = prepare_text(df_train)  #,  dev_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>question_token</th>\n",
       "      <th>answer_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>[when, did, beyonce, start, becoming, popular]</td>\n",
       "      <td>[in, the, late, 1990s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>[what, areas, did, beyonce, compete, in, when,...</td>\n",
       "      <td>[singing, and, dancing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "      <td>[when, did, beyonce, leave, destinys, child, a...</td>\n",
       "      <td>[2003]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>[in, what, city, and, state, did, beyonce, gro...</td>\n",
       "      <td>[houston, texas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>[in, which, decade, did, beyonce, become, famous]</td>\n",
       "      <td>[late, 1990s]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question              answers  \\\n",
       "0           When did Beyonce start becoming popular?    in the late 1990s   \n",
       "1  What areas did Beyonce compete in when she was...  singing and dancing   \n",
       "2  When did Beyonce leave Destiny's Child and bec...                 2003   \n",
       "3      In what city and state did Beyonce  grow up?        Houston, Texas   \n",
       "4         In which decade did Beyonce become famous?           late 1990s   \n",
       "\n",
       "                                      question_token             answer_token  \n",
       "0     [when, did, beyonce, start, becoming, popular]   [in, the, late, 1990s]  \n",
       "1  [what, areas, did, beyonce, compete, in, when,...  [singing, and, dancing]  \n",
       "2  [when, did, beyonce, leave, destinys, child, a...                   [2003]  \n",
       "3  [in, what, city, and, state, did, beyonce, gro...         [houston, texas]  \n",
       "4  [in, which, decade, did, beyonce, become, famous]            [late, 1990s]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2VectorDict = w2v.wv.key_to_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 55000\n",
    "EOS_token = 55001\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"SOS\": 55000, \"EOS\": 55001}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {55000: \"SOS\", 55001: \"EOS\"}\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "                if word in word2VectorDict:\n",
    "                    indexOfWord = word2VectorDict[word]\n",
    "                    self.word2index[word] = indexOfWord\n",
    "                    self.index2word[indexOfWord] = word\n",
    "                    self.n_words += 1\n",
    "                else:\n",
    "                    self.word2index[word] = self.n_words\n",
    "                    self.index2word[self.n_words] = word\n",
    "                    self.n_words += 1\n",
    "                self.word2count[word] = 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = Lang(name='alltokens')\n",
    "Questionlang = Lang(name='allQuestiontokens')\n",
    "Answerlang = Lang(name='allAnswertokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_train.size)\n",
    "df_train = df_train.head(5000)\n",
    "#print(df_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r, in df_train.iterrows():\n",
    "    text = r['question_token']\n",
    "    if text != None and text != '':\n",
    "        text = [i for i in text if i]\n",
    "        for t in text:\n",
    "            lang.addWord(t)\n",
    "            Questionlang.addWord(t)\n",
    "\n",
    "for i,r, in df_train.iterrows():\n",
    "    text = r['answer_token']\n",
    "    if text != None and text != '':\n",
    "        text = [i for i in text if i]\n",
    "        for t in text:\n",
    "            lang.addWord(t)\n",
    "            Answerlang.addWord(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang.word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(lang.word2count, key=lang.word2count.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i,r, in dev_test.iterrows():\\n    text = r['question_token']\\n    if text != None and text != '':\\n        text = [i for i in text if i]\\n        for t in text:\\n            lang.addWord(t)\\n\\nfor i,r, in dev_test.iterrows():\\n    text = r['answer_token']\\n    if text != None and text != '':\\n        text = [i for i in text if i]\\n        for t in text:\\n            lang.addWord(t)*/\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i,r, in dev_test.iterrows():\n",
    "    text = r['question_token']\n",
    "    if text != None and text != '':\n",
    "        text = [i for i in text if i]\n",
    "        for t in text:\n",
    "            lang.addWord(t)\n",
    "\n",
    "for i,r, in dev_test.iterrows():\n",
    "    text = r['answer_token']\n",
    "    if text != None and text != '':\n",
    "        text = [i for i in text if i]\n",
    "        for t in text:\n",
    "            lang.addWord(t)*/'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\n",
    "  'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentencelist):\n",
    "    if sentencelist != None and sentencelist != '':\n",
    "        sentencelist = [i for i in sentencelist if i]\n",
    "        if len(sentencelist) > 0:\n",
    "            return [lang.word2index[word] for word in sentencelist]\n",
    "    return [];\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "        indexes = indexesFromSentence(lang, sentence)\n",
    "        indexes.append(EOS_token)\n",
    "        indexes.insert(0, SOS_token)\n",
    "        return torch.tensor(indexes, dtype=torch.long, device= device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = [tensorFromSentence(lang, sentencelist) for sentencelist in df_train['question_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = [tensorFromSentence(lang, sentencelist) for sentencelist in df_train['answer_token']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_source_data = [tensorFromSentence(lang, sentencelist) for sentencelist in dev_test['question_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_target_data = [tensorFromSentence(lang, sentencelist) for sentencelist in dev_test['answer_token']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = source_data[0:5000]\n",
    "target_list = target_data[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def split(list_a, chunk_size):\\n    for i in range(0, len(list_a), chunk_size):\\n        yield list_a[i:i + chunk_size]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def split(list_a, chunk_size):\n",
    "    for i in range(0, len(list_a), chunk_size):\n",
    "        yield list_a[i:i + chunk_size]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_target_data = dev_target_data[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_source_data = dev_source_data[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testabc = target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testabc[0][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src = testabc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = src.view(  1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['source_data'] = [tensorFromSentence(lang, sentencelist) for sentencelist in df_train['question_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['target_data'] = [tensorFromSentence(lang, sentencelist) for sentencelist in df_train['answer_token']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_test['source_data'] = [tensorFromSentence(lang, sentencelist) for sentencelist in dev_test['question_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_test['target_data'] = [tensorFromSentence(lang, sentencelist) for sentencelist in dev_test['answer_token']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = df_train\n",
    "#columns = ['question', 'answers']\n",
    "#train_data.drop(columns, inplace=True, axis=1)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.reset_option('max_columns')\n",
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_data = dev_test\n",
    "#columns = ['question', 'answers']\n",
    "#valid_data.drop(columns, inplace=True, axis=1)\n",
    "#valid_data.head()\n",
    "#valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def chunker(seq, size):\n",
    "#    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in chunker(train_data[['source_data', 'target_data']].head(10),2):\n",
    "#    print(i['target_data'])\n",
    "#a = train_data['target_data'].head(1)\n",
    "#a[0].shape[0]\n",
    "#a[0][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "oQLTP2Wmi1eB"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hid_dim, n_layers, dropout):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # self.embedding provides a vector representation of the inputs to our model\n",
    "        \n",
    "        # self.lstm, accepts the vectorized input and passes a hidden state\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_dim, self.hid_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.hid_dim, self.hid_dim, n_layers, dropout = dropout) #\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    #,  \n",
    "    def forward(self, src, hidden, cell_state):\n",
    "        \n",
    "        '''\n",
    "        Inputs: i, the src vector\n",
    "        Outputs: o, the encoder outputs\n",
    "                h, the hidden state\n",
    "                c, the cell state\n",
    "        '''\n",
    "        \n",
    "        #embedded = self.dropout(self.embedding(src))\n",
    "        embedded = self.embedding(src)\n",
    "        embedded = embedded.view(1, 1, -1)\n",
    "        outputs, (hidden, cell) = self.rnn(embedded, (hidden, cell_state))\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return outputs, hidden, cell\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "      \n",
    "    def __init__(self,  output_dim, hid_dim, n_layers, dropout):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # self.embedding provides a vector representation of the target to our model\n",
    "        \n",
    "        # self.lstm, accepts the embeddings and outputs a hidden state\n",
    "\n",
    "        # self.ouput, predicts on the hidden state via a linear output layer\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_dim, self.hid_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.hid_dim, self.hid_dim, n_layers, dropout = dropout) #\n",
    "        \n",
    "        self.fc_out = nn.Linear(self.hid_dim, self.output_dim)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, src, hidden, cell):\n",
    "        \n",
    "        '''\n",
    "        Inputs: i, the target vector\n",
    "        Outputs: o, the prediction\n",
    "                h, the hidden state\n",
    "        '''\n",
    "        \n",
    "              \n",
    "        #embedded = self.dropout(self.embedding(input))     \n",
    "        embedded = self.embedding(src) \n",
    "        embedded = embedded.view(1, 1, -1)       \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "                \n",
    "        prediction = self.fc_out(output[0])\n",
    "        \n",
    "        prediction = self.softmax(prediction)\n",
    "   \n",
    "        return prediction, hidden, cell\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, src, trg, src_len, trg_len, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        output = {\n",
    "            'decoder_output':[]\n",
    "        }\n",
    "\n",
    "        encoder_hidden = torch.zeros([2, 1, self.encoder.hid_dim]).to(self.device) # 1 = number of LSTM layers\n",
    "        cell_state = torch.zeros([2, 1, self.encoder.hid_dim]).to(self.device)\n",
    "        \n",
    "        for i in range(src_len):\n",
    "            encoder_output, encoder_hidden, cell_state = self.encoder(src[i], encoder_hidden, cell_state)\n",
    "            #hidden, cell = self.encoder(src)\n",
    "        \n",
    "        \n",
    "        #input = trg[0,:]\n",
    "        decoder_input = trg[0,:] #torch.Tensor([[55000]]).to(self.device) # 0 = SOS_token\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        for t in range(trg_len):\n",
    "            decoder_output, decoder_hidden, cell_state  = self.decoder(decoder_input, decoder_hidden, cell_state)\n",
    "            output['decoder_output'].append(decoder_output)\n",
    "            \n",
    "            if self.training: # Model not in eval mode\n",
    "                decoder_input = target_tensor[i] if random.random() > teacher_forcing_ratio else decoder_output.argmax(1) # teacher forcing\n",
    "            else:\n",
    "                _, top_index = decoder_output.data.topk(1)\n",
    "                decoder_input = top_index.squeeze().detach()\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5855\n",
      "5855\n",
      "4432\n",
      "4432\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM =  len(Questionlang.word2index) #len(SRC.vocab)\n",
    "print(INPUT_DIM)\n",
    "print(Questionlang.n_words)\n",
    "OUTPUT_DIM = len(Answerlang.word2index) #len(TRG.vocab)\n",
    "print(OUTPUT_DIM)\n",
    "print(Answerlang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM =  len(Questionlang.word2index) #len(SRC.vocab)\n",
    "OUTPUT_DIM = len(Answerlang.word2index) #len(TRG.vocab)\n",
    "\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "modelSeq2Seq = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def init_weights(m):\n",
    "#    for name, param in m.named_parameters():\n",
    "#        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "#modelSeq2Seq.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def count_parameters(model):\n",
    "#    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "#print(f'The model has {count_parameters(modelSeq2Seq):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(modelSeq2Seq.parameters())\n",
    "#criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    " #ignore_index = TRG_PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(modelSeq2Seq.parameters(), lr=0.01)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train(model, source_data, target_data, optimizer, criterion, epochs, print_every, batch_size):\n",
    "    \n",
    "    #model.to(device)\n",
    "    best_valid_loss = float('inf')\n",
    "    total_training_loss = 0\n",
    "    total_valid_loss = 0\n",
    "    loss = 0\n",
    "    \n",
    "    kf = KFold(n_splits=epochs, shuffle=True)\n",
    "    for e, (train_index, test_index) in enumerate(kf.split(source_data), 1):\n",
    "        model.train()\n",
    "        \n",
    "        for i in range(0, len(train_index)):\n",
    "            src = source_data[i]\n",
    "            trg = target_data[i]\n",
    "            print(trg[0,:])\n",
    "            output = model(src, trg, src.size(0), trg.size(0))\n",
    "            print(output)\n",
    "        \n",
    "        current_loss = 0\n",
    "        for (s, t) in zip(output[\"decoder_output\"], trg): \n",
    "                current_loss += criterion(s, t)\n",
    "\n",
    "        loss += current_loss\n",
    "        total_training_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
    "        \n",
    "        if i % batch_size == 0 or i == (len(train_index)-1):\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    for i in range(0, len(test_index)):\n",
    "        src = source_data[i]\n",
    "        trg = target_data[i]\n",
    "\n",
    "        output = model(src, trg, src.size(0), trg.size(0))\n",
    "\n",
    "        current_loss = 0\n",
    "        for (s, t) in zip(output[\"decoder_output\"], trg): \n",
    "            current_loss += criterion(s, t)\n",
    "            total_valid_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
    "    \n",
    "    if e % print_every == 0:\n",
    "            training_loss_average = total_training_loss / (len(train_index)*print_every)\n",
    "            validation_loss_average = total_valid_loss / (len(test_index)*print_every)\n",
    "            print(\"{}/{} Epoch  -  Training Loss = {:.4f}  -  Validation Loss = {:.4f}\".format(e, epochs, training_loss_average, validation_loss_average))\n",
    "            total_training_loss = 0\n",
    "            total_valid_loss = 0 \n",
    "            \n",
    "    if validation_loss_average < best_valid_loss:\n",
    "        best_valid_loss = validation_loss_average\n",
    "        torch.save(model.state_dict(), 'chatbot-model.pt')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([55000])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-624b3f7700c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprint_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       batch_size = 128)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-15ec976fc988>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, source_data, target_data, optimizer, criterion, epochs, print_every, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-5b1994decf8f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, src_len, trg_len, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;31m#hidden, cell = self.encoder(src)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-5b1994decf8f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, hidden, cell_state)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#embedded = self.dropout(self.embedding(src))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2181\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "train(model = modelSeq2Seq,\n",
    "      source_data = source_list,\n",
    "      target_data = target_list,\n",
    "      optimizer = optimizer,\n",
    "      criterion = criterion,\n",
    "      epochs = 65,\n",
    "      print_every = 5,\n",
    "      batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
