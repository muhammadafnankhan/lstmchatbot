{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install dataloader\n",
    "#from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eg81uNTWixbi",
    "outputId": "9c0f9eda-75fb-4526-e9b6-f9a76eeeb007"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import torch\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pandas.io.json import json_normalize \n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Output, save, and load brown embeddings\n",
    "\n",
    "model = gensim.models.Word2Vec(brown.sents())\n",
    "model.save('brown.embedding')\n",
    "\n",
    "w2v = gensim.models.Word2Vec.load('brown.embedding')\n",
    "\n",
    "def clean_text(x):\n",
    "    if len(x) > 0:\n",
    "        return x[0][\"text\"]\n",
    "\n",
    "def loadDF(path):\n",
    "    \n",
    "    df = pd.read_json(path) \n",
    "    data = pd.json_normalize(data = df['data'],\n",
    "                            record_path =['paragraphs', 'qas'])\n",
    "    data = data.drop('id', axis=1)\n",
    "    data = data.drop('is_impossible', axis=1)\n",
    "    data = data.drop('plausible_answers', axis=1)\n",
    "    data['answers'] = data['answers'].apply(clean_text)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def tokenize_en(text):\n",
    "    if text != None:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        return [tok.lower().strip() for tok in word_tokenize(text)]\n",
    "    return;\n",
    "\n",
    "def prepare_text(df_train, dev_test):\n",
    "    \n",
    "    for i,r, in df_train.iterrows():\n",
    "        answerlist = r['answers']\n",
    "        if answerlist != None:\n",
    "            answerlist = [i for i in answerlist if i]\n",
    "            if len(answerlist) == 0:\n",
    "                r['answers'] =  np.NaN\n",
    "                     \n",
    "    df_train = df_train.dropna(axis=0, subset=['answers'])\n",
    "    df_train.reset_index(drop=True)\n",
    "   \n",
    "    \n",
    "    df_train['question_token'] = df_train['question'].apply(tokenize_en)\n",
    "    df_train['answer_token'] = df_train['answers'].apply(tokenize_en) \n",
    "    \n",
    "    dev_test['question_token'] = dev_test['question'].apply(tokenize_en)\n",
    "    dev_test['answer_token'] = dev_test['answers'].apply(tokenize_en) \n",
    "    \n",
    "    return df_train, dev_test\n",
    "\n",
    "\n",
    "\n",
    "def train_test_split(SRC, TRG):\n",
    "    \n",
    "    '''\n",
    "    Input: SRC, our list of questions from the dataset\n",
    "            TRG, our list of responses from the dataset\n",
    "\n",
    "    Output: Training and test datasets for SRC & TRG\n",
    "\n",
    "    '''\n",
    "    \n",
    "    return SRC_train_dataset, SRC_test_dataset, TRG_train_dataset, TRG_test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = loadDF('./train-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test = loadDF('./dev-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question              answers\n",
       "0           When did Beyonce start becoming popular?    in the late 1990s\n",
       "1  What areas did Beyonce compete in when she was...  singing and dancing\n",
       "2  When did Beyonce leave Destiny's Child and bec...                 2003\n",
       "3      In what city and state did Beyonce  grow up?        Houston, Texas\n",
       "4         In which decade did Beyonce become famous?           late 1990s"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who was the Norse leader?</td>\n",
       "      <td>Rollo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What century did the Normans first gain their ...</td>\n",
       "      <td>10th century</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0               In what country is Normandy located?   \n",
       "1                 When were the Normans in Normandy?   \n",
       "2      From which countries did the Norse originate?   \n",
       "3                          Who was the Norse leader?   \n",
       "4  What century did the Normans first gain their ...   \n",
       "\n",
       "                       answers  \n",
       "0                       France  \n",
       "1      10th and 11th centuries  \n",
       "2  Denmark, Iceland and Norway  \n",
       "3                        Rollo  \n",
       "4                 10th century  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_train,  dev_test = prepare_text(df_train,  dev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>question_token</th>\n",
       "      <th>answer_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>[when, did, beyonce, start, becoming, popular]</td>\n",
       "      <td>[in, the, late, 1990s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>[what, areas, did, beyonce, compete, in, when,...</td>\n",
       "      <td>[singing, and, dancing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "      <td>[when, did, beyonce, leave, destinys, child, a...</td>\n",
       "      <td>[2003]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>[in, what, city, and, state, did, beyonce, gro...</td>\n",
       "      <td>[houston, texas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>[in, which, decade, did, beyonce, become, famous]</td>\n",
       "      <td>[late, 1990s]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question              answers  \\\n",
       "0           When did Beyonce start becoming popular?    in the late 1990s   \n",
       "1  What areas did Beyonce compete in when she was...  singing and dancing   \n",
       "2  When did Beyonce leave Destiny's Child and bec...                 2003   \n",
       "3      In what city and state did Beyonce  grow up?        Houston, Texas   \n",
       "4         In which decade did Beyonce become famous?           late 1990s   \n",
       "\n",
       "                                      question_token             answer_token  \n",
       "0     [when, did, beyonce, start, becoming, popular]   [in, the, late, 1990s]  \n",
       "1  [what, areas, did, beyonce, compete, in, when,...  [singing, and, dancing]  \n",
       "2  [when, did, beyonce, leave, destinys, child, a...                   [2003]  \n",
       "3  [in, what, city, and, state, did, beyonce, gro...         [houston, texas]  \n",
       "4  [in, which, decade, did, beyonce, become, famous]            [late, 1990s]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>question_token</th>\n",
       "      <th>answer_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>France</td>\n",
       "      <td>[in, what, country, is, normandy, located]</td>\n",
       "      <td>[france]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>[when, were, the, normans, in, normandy]</td>\n",
       "      <td>[10th, and, 11th, centuries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>[from, which, countries, did, the, norse, orig...</td>\n",
       "      <td>[denmark, iceland, and, norway]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who was the Norse leader?</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>[who, was, the, norse, leader]</td>\n",
       "      <td>[rollo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What century did the Normans first gain their ...</td>\n",
       "      <td>10th century</td>\n",
       "      <td>[what, century, did, the, normans, first, gain...</td>\n",
       "      <td>[10th, century]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0               In what country is Normandy located?   \n",
       "1                 When were the Normans in Normandy?   \n",
       "2      From which countries did the Norse originate?   \n",
       "3                          Who was the Norse leader?   \n",
       "4  What century did the Normans first gain their ...   \n",
       "\n",
       "                       answers  \\\n",
       "0                       France   \n",
       "1      10th and 11th centuries   \n",
       "2  Denmark, Iceland and Norway   \n",
       "3                        Rollo   \n",
       "4                 10th century   \n",
       "\n",
       "                                      question_token  \\\n",
       "0         [in, what, country, is, normandy, located]   \n",
       "1           [when, were, the, normans, in, normandy]   \n",
       "2  [from, which, countries, did, the, norse, orig...   \n",
       "3                     [who, was, the, norse, leader]   \n",
       "4  [what, century, did, the, normans, first, gain...   \n",
       "\n",
       "                      answer_token  \n",
       "0                         [france]  \n",
       "1     [10th, and, 11th, centuries]  \n",
       "2  [denmark, iceland, and, norway]  \n",
       "3                          [rollo]  \n",
       "4                  [10th, century]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2VectorDict = w2v.wv.key_to_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 55000\n",
    "EOS_token = 55001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"SOS\": 55000, \"EOS\": 55001}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {55000: \"SOS\", 55001: \"EOS\"}\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "                if word in word2VectorDict:\n",
    "                    indexOfWord = word2VectorDict[word]\n",
    "                    self.word2index[word] = indexOfWord\n",
    "                    self.index2word[indexOfWord] = word\n",
    "                    self.n_words += 1\n",
    "                else:\n",
    "                    self.word2index[word] = self.n_words\n",
    "                    self.index2word[self.n_words] = word\n",
    "                    self.n_words += 1\n",
    "                self.word2count[word] = 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = Lang(name='alltokens')\n",
    "Questionlang = Lang(name='allQuestiontokens')\n",
    "Answerlang = Lang(name='allAnswertokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347284\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(df_train.size)\n",
    "df_train = df_train.head(5000)\n",
    "print(df_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r, in df_train.iterrows():\n",
    "    text = r['question_token']\n",
    "    if text != None and text != '':\n",
    "        text = [i for i in text if i]\n",
    "        for t in text:\n",
    "            lang.addWord(t)\n",
    "            Questionlang.addWord(t)\n",
    "\n",
    "for i,r, in df_train.iterrows():\n",
    "    text = r['answer_token']\n",
    "    if text != None and text != '':\n",
    "        text = [i for i in text if i]\n",
    "        for t in text:\n",
    "            lang.addWord(t)\n",
    "            Answerlang.addWord(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SOS': 55000,\n",
       " 'EOS': 55001,\n",
       " 'when': 71,\n",
       " 'did': 105,\n",
       " 'beyonce': 4,\n",
       " 'start': 728,\n",
       " 'becoming': 2011,\n",
       " 'popular': 1141,\n",
       " 'what': 79,\n",
       " 'areas': 420,\n",
       " 'compete': 4477,\n",
       " 'in': 7,\n",
       " 'she': 58,\n",
       " 'was': 10,\n",
       " 'growing': 1025,\n",
       " 'up': 61,\n",
       " 'leave': 485,\n",
       " 'destinys': 17,\n",
       " 'child': 461,\n",
       " 'and': 4,\n",
       " 'become': 270,\n",
       " 'a': 6,\n",
       " 'solo': 10641,\n",
       " 'singer': 9817,\n",
       " 'city': 375,\n",
       " 'state': 182,\n",
       " 'grow': 1774,\n",
       " 'which': 35,\n",
       " 'decade': 2422,\n",
       " 'famous': 1232,\n",
       " 'rb': 30,\n",
       " 'group': 248,\n",
       " 'the': 0,\n",
       " 'lead': 825,\n",
       " 'album': 11822,\n",
       " 'made': 97,\n",
       " 'her': 40,\n",
       " 'worldwide': 37,\n",
       " 'known': 400,\n",
       " 'artist': 2053,\n",
       " 'who': 53,\n",
       " 'managed': 3109,\n",
       " 'beyoncé': 42,\n",
       " 'rise': 1077,\n",
       " 'to': 5,\n",
       " 'fame': 5979,\n",
       " 'role': 1044,\n",
       " 'have': 33,\n",
       " 'first': 87,\n",
       " 'released': 4046,\n",
       " 'as': 17,\n",
       " 'release': 3132,\n",
       " 'dangerously': 52,\n",
       " 'love': 453,\n",
       " 'how': 159,\n",
       " 'many': 112,\n",
       " 'grammy': 56,\n",
       " 'awards': 5808,\n",
       " 'win': 2057,\n",
       " 'for': 11,\n",
       " 'beyoncés': 60,\n",
       " 'name': 335,\n",
       " 'of': 3,\n",
       " 'after': 123,\n",
       " 'second': 292,\n",
       " 'other': 74,\n",
       " 'entertainment': 3716,\n",
       " 'venture': 5256,\n",
       " 'explore': 7333,\n",
       " 'marry': 5399,\n",
       " 'set': 231,\n",
       " 'record': 770,\n",
       " 'grammys': 72,\n",
       " 'movie': 3765,\n",
       " 'receive': 1465,\n",
       " 'golden': 4210,\n",
       " 'globe': 7762,\n",
       " 'nomination': 7666,\n",
       " 'take': 172,\n",
       " 'hiatus': 79,\n",
       " 'career': 1637,\n",
       " 'control': 464,\n",
       " 'management': 1242,\n",
       " 'darker': 83,\n",
       " 'tone': 1490,\n",
       " 'from': 30,\n",
       " 'previous': 1301,\n",
       " 'work': 135,\n",
       " 'portraying': 88,\n",
       " 'etta': 89,\n",
       " 'james': 90,\n",
       " 'create': 2131,\n",
       " 'sasha': 92,\n",
       " 'fierce': 10963,\n",
       " 'end': 236,\n",
       " 'their': 47,\n",
       " 'act': 595,\n",
       " 'acting': 2184,\n",
       " 'job': 418,\n",
       " '2006': 99,\n",
       " 'is': 9,\n",
       " 'married': 1074,\n",
       " 'alterego': 102,\n",
       " 'music': 505,\n",
       " 'are': 29,\n",
       " 'some': 80,\n",
       " 'recurring': 12311,\n",
       " 'elements': 1052,\n",
       " 'them': 65,\n",
       " 'time': 77,\n",
       " 'magazine': 3453,\n",
       " 'named': 1345,\n",
       " 'one': 41,\n",
       " 'most': 99,\n",
       " '100': 1424,\n",
       " 'people': 125,\n",
       " 'century': 535,\n",
       " 'declared': 1693,\n",
       " 'dominant': 1786,\n",
       " 'woman': 442,\n",
       " 'musician': 4474,\n",
       " 'recording': 3739,\n",
       " 'industry': 627,\n",
       " 'association': 2439,\n",
       " 'america': 124,\n",
       " 'recognize': 1793,\n",
       " 'top': 483,\n",
       " 'certified': 11359,\n",
       " 'rated': 9525,\n",
       " 'powerful': 1802,\n",
       " 'female': 2352,\n",
       " '2015': 131,\n",
       " 'describe': 2726,\n",
       " 'herself': 835,\n",
       " 'feminist': 134,\n",
       " 'years': 109,\n",
       " 'rate': 462,\n",
       " 'influential': 7290,\n",
       " 'world': 145,\n",
       " 'records': 1287,\n",
       " 'has': 51,\n",
       " 'sold': 2402,\n",
       " '19': 3474,\n",
       " 'year': 153,\n",
       " 'sell': 2803,\n",
       " 'part': 201,\n",
       " 'leaving': 1382,\n",
       " 'under': 154,\n",
       " 'own': 130,\n",
       " 'won': 1604,\n",
       " 'beyonces': 150,\n",
       " 'younger': 2800,\n",
       " 'sibling': 152,\n",
       " 'also': 103,\n",
       " 'sang': 3793,\n",
       " 'with': 15,\n",
       " 'band': 2559,\n",
       " 'where': 120,\n",
       " 'get': 141,\n",
       " 'race': 1097,\n",
       " 'father': 634,\n",
       " 'childhood': 2290,\n",
       " 'home': 190,\n",
       " 'believed': 1440,\n",
       " 'religion': 1080,\n",
       " 'worked': 809,\n",
       " 'sales': 830,\n",
       " 'manager': 1384,\n",
       " 'company': 440,\n",
       " 'mother': 516,\n",
       " 'sister': 3276,\n",
       " 'appeared': 756,\n",
       " 'descendent': 172,\n",
       " 'arcadian': 173,\n",
       " 'leader': 1592,\n",
       " 'descendant': 175,\n",
       " 'acadian': 176,\n",
       " 'raised': 1086,\n",
       " 'town': 477,\n",
       " 'go': 166,\n",
       " 'school': 226,\n",
       " 'person': 587,\n",
       " 'notice': 2084,\n",
       " 'singing': 2578,\n",
       " 'ability': 1494,\n",
       " 'moved': 548,\n",
       " 'left': 198,\n",
       " 'elementary': 6211,\n",
       " 'teachers': 1748,\n",
       " 'discovered': 1507,\n",
       " 'musical': 1386,\n",
       " 'talent': 2810,\n",
       " 'i': 192,\n",
       " 'church': 433,\n",
       " 'member': 776,\n",
       " 'soloist': 9343,\n",
       " 'choir': 196,\n",
       " 'type': 490,\n",
       " 'parker': 198,\n",
       " 'song': 2007,\n",
       " 'sing': 3951,\n",
       " 'competition': 2041,\n",
       " 'at': 26,\n",
       " 'age': 447,\n",
       " '7': 1150,\n",
       " 'located': 1766,\n",
       " 'dance': 1328,\n",
       " 'instructor': 10164,\n",
       " 'old': 176,\n",
       " 'show': 357,\n",
       " 'two': 83,\n",
       " 'decided': 721,\n",
       " 'place': 188,\n",
       " 'star': 6167,\n",
       " 'search': 1708,\n",
       " '1995': 215,\n",
       " 'manage': 5147,\n",
       " 'girls': 741,\n",
       " 'label': 5299,\n",
       " 'give': 250,\n",
       " 'deal': 766,\n",
       " 'brought': 388,\n",
       " 'california': 222,\n",
       " 'enter': 1407,\n",
       " 'quit': 7282,\n",
       " 'his': 19,\n",
       " 'large': 281,\n",
       " 'recorded': 2654,\n",
       " 'groups': 828,\n",
       " 'signed': 3089,\n",
       " 'later': 276,\n",
       " 'cut': 550,\n",
       " 'meet': 695,\n",
       " 'latavia': 233,\n",
       " 'robertson': 234,\n",
       " 'met': 801,\n",
       " 'roberson': 236,\n",
       " 'placed': 826,\n",
       " 'tyme': 238,\n",
       " 'begin': 1340,\n",
       " 'girl': 459,\n",
       " 'on': 20,\n",
       " 'october': 242,\n",
       " '5': 720,\n",
       " 'film': 1159,\n",
       " 'featured': 10502,\n",
       " 'childs': 246,\n",
       " 'major': 427,\n",
       " 'single': 570,\n",
       " 'award': 2868,\n",
       " 'best': 291,\n",
       " 'performance': 856,\n",
       " 'man': 95,\n",
       " 'changed': 1149,\n",
       " 'based': 912,\n",
       " 'quote': 5809,\n",
       " 'book': 558,\n",
       " 'bible': 257,\n",
       " 'debut': 6595,\n",
       " 'killing': 4516,\n",
       " 'movies': 3695,\n",
       " 'sound': 475,\n",
       " 'track': 3039,\n",
       " '43': 15090,\n",
       " 'annual': 1225,\n",
       " 'included': 1153,\n",
       " 'films': 3681,\n",
       " 'soundtrack': 267,\n",
       " 'hit': 950,\n",
       " 'duet': 269,\n",
       " 'mental': 2740,\n",
       " 'health': 1235,\n",
       " 'issue': 707,\n",
       " 'through': 110,\n",
       " 'event': 1365,\n",
       " 'occured': 275,\n",
       " 'publicly': 4176,\n",
       " 'criticized': 6655,\n",
       " 'supported': 2101,\n",
       " 'depression': 4533,\n",
       " 'caused': 1212,\n",
       " 'long': 143,\n",
       " 'depressed': 8285,\n",
       " 'helped': 1663,\n",
       " 'fight': 1122,\n",
       " 'replaced': 2713,\n",
       " 'luckett': 286,\n",
       " 'blamed': 10859,\n",
       " 'overcome': 4081,\n",
       " 'during': 206,\n",
       " 'following': 471,\n",
       " 'split': 3797,\n",
       " 'newest': 7617,\n",
       " 'removed': 1474,\n",
       " 'charlies': 294,\n",
       " 'angels': 8760,\n",
       " 'members': 313,\n",
       " 'weeks': 737,\n",
       " 'independent': 1671,\n",
       " 'women': 541,\n",
       " 'stay': 1008,\n",
       " 'network': 3658,\n",
       " 'land': 484,\n",
       " 'third': 577,\n",
       " 'survivor': 304,\n",
       " 'its': 68,\n",
       " 'week': 383,\n",
       " 'french': 307,\n",
       " 'composer': 3546,\n",
       " 'wrote': 543,\n",
       " 'original': 1066,\n",
       " 'opera': 3995,\n",
       " 'carmen': 312,\n",
       " '19th': 10400,\n",
       " 'lawsuit': 314,\n",
       " 'be': 21,\n",
       " 'filed': 3412,\n",
       " '2001': 317,\n",
       " '2000': 15110,\n",
       " 'mekhi': 319,\n",
       " 'phifer': 320,\n",
       " 'destiny': 4616,\n",
       " 'over': 90,\n",
       " 'announce': 5600,\n",
       " 'austin': 324,\n",
       " 'powers': 1644,\n",
       " 'goldmember': 326,\n",
       " 'three': 180,\n",
       " 'countries': 684,\n",
       " 'it': 16,\n",
       " 'out': 55,\n",
       " 'achieve': 2208,\n",
       " 'ten': 682,\n",
       " 'status': 1137,\n",
       " 'starred': 334,\n",
       " 'cuba': 335,\n",
       " 'gooding': 336,\n",
       " 'jr': 337,\n",
       " 'fighting': 1757,\n",
       " 'temptations': 12739,\n",
       " 'better': 233,\n",
       " 'charts': 9872,\n",
       " 'appear': 908,\n",
       " 'mike': 343,\n",
       " 'myers': 344,\n",
       " 'amount': 572,\n",
       " 'gross': 4134,\n",
       " 'genre': 347,\n",
       " 'critics': 4048,\n",
       " 'view': 540,\n",
       " '2002': 350,\n",
       " 'character': 903,\n",
       " 'called': 238,\n",
       " 'goldmembers': 353,\n",
       " 'comedy': 3084,\n",
       " 'along': 290,\n",
       " '2003': 356,\n",
       " 'tempations': 357,\n",
       " 'highest': 1806,\n",
       " 'achieved': 1811,\n",
       " 'billboard': 360,\n",
       " 'hot': 892,\n",
       " 'by': 24,\n",
       " 'sould': 363,\n",
       " 'since': 205,\n",
       " 'number': 200,\n",
       " 'five': 407,\n",
       " 'singles': 367,\n",
       " 'came': 161,\n",
       " 'us': 150,\n",
       " 'spot': 2045,\n",
       " 'chart': 5672,\n",
       " 'closer': 1872,\n",
       " 'you': 43,\n",
       " 'associated': 1970,\n",
       " 'premiere': 14126,\n",
       " 'earn': 5967,\n",
       " 'duo': 377,\n",
       " 'or': 31,\n",
       " '46th': 379,\n",
       " 'final': 667,\n",
       " 'got': 199,\n",
       " 'hollywood': 382,\n",
       " 'walk': 1140,\n",
       " 'embark': 14612,\n",
       " 'tour': 2748,\n",
       " 'europe': 386,\n",
       " 'announced': 1238,\n",
       " 'that': 8,\n",
       " 'would': 45,\n",
       " 'disban': 390,\n",
       " 'european': 391,\n",
       " 'started': 499,\n",
       " 'november': 393,\n",
       " 'verizon': 394,\n",
       " 'lades': 395,\n",
       " 'perform': 3712,\n",
       " 'february': 397,\n",
       " '1': 189,\n",
       " '2004': 399,\n",
       " 'studio': 3892,\n",
       " 'albums': 401,\n",
       " 'irreplaceable': 402,\n",
       " 'produce': 1337,\n",
       " 'birthday': 5597,\n",
       " 'bday': 405,\n",
       " 'celebrate': 406,\n",
       " 'deja': 10745,\n",
       " 'vu': 408,\n",
       " 'high': 204,\n",
       " 'climb': 8130,\n",
       " 'copies': 5674,\n",
       " 'collaborated': 9025,\n",
       " 'only': 73,\n",
       " 'uk': 414,\n",
       " 'listen': 3337,\n",
       " 'much': 114,\n",
       " 'money': 377,\n",
       " 'make': 131,\n",
       " '2007': 419,\n",
       " 'millions': 2279,\n",
       " 'dollars': 1128,\n",
       " 'pink': 2459,\n",
       " 'panther': 423,\n",
       " 'call': 547,\n",
       " 'concert': 3213,\n",
       " 'beautiful': 858,\n",
       " 'liar': 427,\n",
       " 'steve': 428,\n",
       " 'martin': 429,\n",
       " 'dreamgirls': 430,\n",
       " 'pop': 13942,\n",
       " 'international': 901,\n",
       " '2008': 433,\n",
       " 'whom': 716,\n",
       " 'amsasha': 435,\n",
       " 'more': 54,\n",
       " 'songs': 1972,\n",
       " 'than': 64,\n",
       " 'any': 84,\n",
       " 'beat': 1728,\n",
       " 'video': 441,\n",
       " '2009': 442,\n",
       " 'grossed': 443,\n",
       " 'reveal': 3649,\n",
       " 'marriage': 1183,\n",
       " 'alter': 6422,\n",
       " 'ego': 7320,\n",
       " 'mtv': 448,\n",
       " 'prominent': 2804,\n",
       " 'felt': 275,\n",
       " 'should': 118,\n",
       " 'went': 194,\n",
       " 'instead': 803,\n",
       " 'taylor': 454,\n",
       " 'swift': 6970,\n",
       " 'portrayed': 12016,\n",
       " 'cadillac': 457,\n",
       " 'gave': 341,\n",
       " 'entire': 680,\n",
       " 'salary': 2729,\n",
       " 'organization': 965,\n",
       " 'couples': 7095,\n",
       " 'inaugural': 14502,\n",
       " 'ball': 1088,\n",
       " 'obsessed': 14770,\n",
       " 'scene': 1065,\n",
       " 'donate': 467,\n",
       " 'thriller': 468,\n",
       " 'played': 1056,\n",
       " 'buget': 470,\n",
       " 'portray': 11863,\n",
       " 'received': 611,\n",
       " 'january': 473,\n",
       " '20': 1181,\n",
       " 'ali': 475,\n",
       " 'larter': 476,\n",
       " 'nominated': 10549,\n",
       " '52nd': 478,\n",
       " 'tied': 3270,\n",
       " 'nominations': 480,\n",
       " '2010': 481,\n",
       " 'now': 100,\n",
       " 'telephone': 1694,\n",
       " 'sixth': 5106,\n",
       " 'else': 560,\n",
       " 'they': 42,\n",
       " 'tie': 4669,\n",
       " 'six': 493,\n",
       " 'ceremony': 5394,\n",
       " 'artists': 2609,\n",
       " 'singers': 6926,\n",
       " 'lady': 2338,\n",
       " 'gaga': 493,\n",
       " 'hits': 4900,\n",
       " '1992': 495,\n",
       " 'break': 1265,\n",
       " 'business': 266,\n",
       " 'ways': 821,\n",
       " 'landmark': 499,\n",
       " 'see': 140,\n",
       " 'china': 11837,\n",
       " 'inspired': 4208,\n",
       " 'this': 32,\n",
       " 'stop': 967,\n",
       " 'using': 778,\n",
       " 'last': 157,\n",
       " 'suggested': 1054,\n",
       " 'reports': 1409,\n",
       " 'about': 69,\n",
       " 'performing': 5804,\n",
       " 'muammar': 511,\n",
       " 'gaddafi': 512,\n",
       " 'surface': 486,\n",
       " 'earned': 5417,\n",
       " 'shows': 1161,\n",
       " 'became': 402,\n",
       " 'stage': 568,\n",
       " 'spokespeople': 518,\n",
       " 'confirm': 6043,\n",
       " 'donations': 520,\n",
       " 'listed': 2719,\n",
       " '2011': 522,\n",
       " 'paid': 708,\n",
       " 'performer': 11202,\n",
       " 'per': 258,\n",
       " 'hoe': 526,\n",
       " 'everyone': 1520,\n",
       " 'learn': 1318,\n",
       " 'performed': 3271,\n",
       " 'kaddafi': 530,\n",
       " 'leak': 531,\n",
       " 'happen': 1754,\n",
       " 'tell': 399,\n",
       " 'donation': 534,\n",
       " 'privately': 8685,\n",
       " 'information': 378,\n",
       " 'libyan': 537,\n",
       " 'ruler': 538,\n",
       " 'pay': 590,\n",
       " 'private': 528,\n",
       " 'headline': 541,\n",
       " 'glastonbury': 542,\n",
       " 'festival': 7442,\n",
       " 'fourth': 1882,\n",
       " 'debuted': 545,\n",
       " 'had': 25,\n",
       " 'success': 1279,\n",
       " 'an': 34,\n",
       " 'activity': 917,\n",
       " 'four': 301,\n",
       " 'nights': 3566,\n",
       " 'forth': 1544,\n",
       " 'awarded': 5842,\n",
       " 'writing': 959,\n",
       " 'roseland': 555,\n",
       " 'ballroom': 11392,\n",
       " '4': 468,\n",
       " 'write': 1027,\n",
       " 'story': 685,\n",
       " 'earlier': 712,\n",
       " 'standing': 1134,\n",
       " 'room': 262,\n",
       " 'concerts': 4781,\n",
       " 'birth': 1761,\n",
       " 'appearance': 1976,\n",
       " 'giving': 1176,\n",
       " 'before': 108,\n",
       " 'again': 185,\n",
       " 'atlantic': 569,\n",
       " 'daughter': 1574,\n",
       " 'blue': 1124,\n",
       " 'ivy': 572,\n",
       " 'born': 974,\n",
       " 'public': 234,\n",
       " 'play': 489,\n",
       " 'resort': 7720,\n",
       " 'compilation': 8704,\n",
       " 'topic': 9545,\n",
       " 'documentary': 579,\n",
       " 'sign': 1201,\n",
       " '2013': 581,\n",
       " 'title': 2182,\n",
       " 'added': 576,\n",
       " 'whose': 393,\n",
       " 'inauguration': 585,\n",
       " 'national': 455,\n",
       " 'anthem': 587,\n",
       " 'tweets': 588,\n",
       " 'minute': 2120,\n",
       " 'half': 372,\n",
       " 'new': 98,\n",
       " 'president': 833,\n",
       " 'obamas': 593,\n",
       " 'month': 794,\n",
       " 'dates': 3619,\n",
       " 'mrs': 596,\n",
       " 'carter': 597,\n",
       " 'entail': 15015,\n",
       " 'successful': 1175,\n",
       " 'tours': 9567,\n",
       " 'yet': 342,\n",
       " 'epic': 5514,\n",
       " 'voiced': 14457,\n",
       " 'animated': 14338,\n",
       " 'honorary': 605,\n",
       " 'chair': 1688,\n",
       " 'voice': 437,\n",
       " 'april': 608,\n",
       " '15': 941,\n",
       " 'amy': 610,\n",
       " 'winehouse': 611,\n",
       " 'cover': 1284,\n",
       " 'may': 85,\n",
       " '2014': 614,\n",
       " '5th': 615,\n",
       " 'huge': 2160,\n",
       " 'surprise': 2271,\n",
       " 'fifth': 4738,\n",
       " 'consecutive': 8587,\n",
       " 'joined': 2081,\n",
       " 'run': 470,\n",
       " 'reported': 888,\n",
       " 'e': 623,\n",
       " 'earning': 9191,\n",
       " 'were': 37,\n",
       " 'earnings': 5271,\n",
       " 'digital': 12329,\n",
       " 'days': 251,\n",
       " 'husband': 787,\n",
       " 'featuring': 630,\n",
       " 'both': 156,\n",
       " 'jay': 632,\n",
       " 'z': 633,\n",
       " '57th': 634,\n",
       " 'pose': 7993,\n",
       " 'august': 636,\n",
       " 'superbowl': 637,\n",
       " '50': 1835,\n",
       " 'took': 220,\n",
       " 'lost': 566,\n",
       " 'next': 267,\n",
       " 'if': 78,\n",
       " 'grammies': 643,\n",
       " 'model': 1783,\n",
       " 'british': 645,\n",
       " 'entertainer': 646,\n",
       " 'making': 389,\n",
       " 'black': 652,\n",
       " 'do': 86,\n",
       " 'so': 70,\n",
       " 'super': 12886,\n",
       " 'bowl': 5092,\n",
       " 'formation': 3076,\n",
       " 'online': 654,\n",
       " 'service': 401,\n",
       " 'day': 160,\n",
       " 'streaming': 11370,\n",
       " 'kind': 321,\n",
       " 'platform': 1567,\n",
       " 'exclusively': 4331,\n",
       " 'together': 374,\n",
       " 'pregnant': 10042,\n",
       " 'described': 871,\n",
       " 'hardest': 8181,\n",
       " 'thing': 298,\n",
       " 'endure': 10145,\n",
       " 'relationship': 1263,\n",
       " 'miscarriage': 668,\n",
       " 'zs': 669,\n",
       " 'girlfriend': 670,\n",
       " 'creating': 3728,\n",
       " 'speculation': 672,\n",
       " 'combined': 2922,\n",
       " 'saddest': 674,\n",
       " 'life': 149,\n",
       " 'attended': 3142,\n",
       " 'confirmed': 5029,\n",
       " 'watched': 1350,\n",
       " 'pregnancy': 679,\n",
       " 'why': 408,\n",
       " 'broadcast': 5899,\n",
       " 'mostwatched': 682,\n",
       " 'history': 365,\n",
       " 'even': 106,\n",
       " 'guinness': 685,\n",
       " 'searched': 9120,\n",
       " 'term': 1397,\n",
       " 'aug': 688,\n",
       " '29': 4486,\n",
       " 'prior': 2832,\n",
       " 'announcing': 11531,\n",
       " 'google': 692,\n",
       " 'website': 693,\n",
       " 'talked': 1957,\n",
       " 'struggles': 695,\n",
       " 'hospital': 1484,\n",
       " 'baby': 1993,\n",
       " 'delivered': 3070,\n",
       " 'dedicated': 4472,\n",
       " 'does': 211,\n",
       " 'bic': 701,\n",
       " 'stand': 705,\n",
       " 'credited': 7708,\n",
       " 'cries': 12136,\n",
       " 'glory': 5545,\n",
       " 'jayz': 706,\n",
       " 'rally': 8289,\n",
       " 'acquittal': 708,\n",
       " 'presidential': 7816,\n",
       " 'raise': 2229,\n",
       " 'obama': 711,\n",
       " '4040': 712,\n",
       " 'club': 1599,\n",
       " 'endorse': 12528,\n",
       " 'march': 4362,\n",
       " '26': 3446,\n",
       " 'attend': 2108,\n",
       " 'july': 718,\n",
       " 'social': 277,\n",
       " 'media': 7311,\n",
       " 'upload': 721,\n",
       " 'picture': 624,\n",
       " 'paper': 659,\n",
       " 'ballot': 7747,\n",
       " 'interview': 3445,\n",
       " 'asked': 246,\n",
       " 'feminism': 727,\n",
       " 'campaign': 1379,\n",
       " 'encourages': 14428,\n",
       " 'leadership': 1226,\n",
       " 'quoted': 4156,\n",
       " 'saying': 936,\n",
       " 'modernday': 733,\n",
       " 'say': 195,\n",
       " 'contribute': 2617,\n",
       " 'response': 1463,\n",
       " 'speech': 1851,\n",
       " 'ban': 10591,\n",
       " 'bossy': 739,\n",
       " 'encourage': 2509,\n",
       " 'used': 163,\n",
       " 'words': 361,\n",
       " 'nigerian': 743,\n",
       " 'author': 2714,\n",
       " 'flawless': 745,\n",
       " 'females': 5747,\n",
       " 'letter': 733,\n",
       " 'important': 263,\n",
       " 'un': 749,\n",
       " 'summit': 8110,\n",
       " 'focused': 7553,\n",
       " 'developing': 2198,\n",
       " 'funding': 753,\n",
       " 'addressed': 5183,\n",
       " 'these': 89,\n",
       " 'will': 52,\n",
       " 'angela': 757,\n",
       " 'merkel': 758,\n",
       " 'serving': 3027,\n",
       " 'relation': 1791,\n",
       " 'want': 299,\n",
       " 'recipients': 14767,\n",
       " 'focus': 2793,\n",
       " 'whoms': 764,\n",
       " 'family': 317,\n",
       " 'death': 369,\n",
       " 'lots': 2928,\n",
       " 'bail': 11600,\n",
       " 'prison': 2838,\n",
       " 'whos': 770,\n",
       " 'protest': 4584,\n",
       " 'spend': 2135,\n",
       " 'between': 142,\n",
       " 'june': 774,\n",
       " 'highestpaid': 775,\n",
       " 'until': 214,\n",
       " 'total': 463,\n",
       " 'worth': 1197,\n",
       " 'entertainers': 779,\n",
       " '2012': 780,\n",
       " '16': 2091,\n",
       " 'celebrity': 782,\n",
       " 'list': 796,\n",
       " 'couple': 866,\n",
       " 'net': 3654,\n",
       " 'began': 315,\n",
       " 'reporting': 5705,\n",
       " 'starting': 1843,\n",
       " 'ever': 296,\n",
       " 'predicted': 5422,\n",
       " 'billion': 1805,\n",
       " 'range': 656,\n",
       " 'octaves': 793,\n",
       " 'timbre': 794,\n",
       " 'distinctive': 4977,\n",
       " 'critic': 4390,\n",
       " 'versatile': 797,\n",
       " 'era': 3738,\n",
       " 'influenced': 6000,\n",
       " 'style': 1120,\n",
       " 'jody': 801,\n",
       " 'rosen': 802,\n",
       " 'daily': 1104,\n",
       " 'mail': 2706,\n",
       " 'claim': 1119,\n",
       " 'span': 6068,\n",
       " 'centerpiece': 807,\n",
       " 'york': 808,\n",
       " 'times': 368,\n",
       " 'jon': 810,\n",
       " 'pareles': 811,\n",
       " 'calls': 1622,\n",
       " 'velvety': 813,\n",
       " 'vocal': 7283,\n",
       " 'generally': 885,\n",
       " 'categorized': 816,\n",
       " 'besides': 4250,\n",
       " 'genres': 818,\n",
       " 'dabble': 819,\n",
       " 'mostly': 2946,\n",
       " 'releases': 10328,\n",
       " 'english': 822,\n",
       " 'but': 38,\n",
       " 'language': 1024,\n",
       " 'spanish': 825,\n",
       " 'coached': 826,\n",
       " 'american': 827,\n",
       " 'mainly': 3759,\n",
       " 'sung': 5453,\n",
       " 'rerelease': 830,\n",
       " 'usually': 521,\n",
       " 'several': 293,\n",
       " 'recordings': 8393,\n",
       " 'come': 169,\n",
       " 'not': 28,\n",
       " 'aspect': 2392,\n",
       " 'example': 339,\n",
       " 'aimed': 4311,\n",
       " 'towards': 1808,\n",
       " 'male': 3059,\n",
       " 'audience': 923,\n",
       " 'theme': 2063,\n",
       " 'early': 295,\n",
       " 'themes': 9833,\n",
       " 'credits': 10619,\n",
       " 'production': 730,\n",
       " 'empowered': 847,\n",
       " 'addition': 725,\n",
       " 'cowriting': 849,\n",
       " 'rather': 280,\n",
       " 'beats': 851,\n",
       " 'things': 268,\n",
       " 'producers': 6557,\n",
       " 'songwriter': 854,\n",
       " 'same': 147,\n",
       " '2': 210,\n",
       " 'african': 857,\n",
       " 'songwriting': 858,\n",
       " '17': 2777,\n",
       " 'songwriters': 860,\n",
       " 'magazines': 4187,\n",
       " 'credit': 2067,\n",
       " 'influence': 780,\n",
       " 'michael': 864,\n",
       " 'jackson': 865,\n",
       " 'kid': 2077,\n",
       " 'tribute': 4432,\n",
       " 'cites': 9174,\n",
       " 'mariah': 869,\n",
       " 'carey': 870,\n",
       " 'doing': 615,\n",
       " 'biggest': 4662,\n",
       " 'feel': 446,\n",
       " 'allaround': 874,\n",
       " 'inspiration': 9306,\n",
       " 'there': 60,\n",
       " 'practice': 1177,\n",
       " 'runs': 2070,\n",
       " 'honor': 1797,\n",
       " 'entertaining': 7454,\n",
       " 'motivated': 8904,\n",
       " 'empowerment': 882,\n",
       " 'wearing': 2420,\n",
       " 'bakers': 884,\n",
       " 'hula': 885,\n",
       " 'skirt': 4861,\n",
       " 'josephine': 887,\n",
       " 'baker': 888,\n",
       " 'noted': 1233,\n",
       " 'proves': 6499,\n",
       " 'can': 72,\n",
       " 'all': 44,\n",
       " 'madonna': 893,\n",
       " 'inspiring': 11920,\n",
       " 'said': 59,\n",
       " 'embodies': 896,\n",
       " 'definition': 3247,\n",
       " 'strong': 503,\n",
       " 'personally': 3184,\n",
       " 'influences': 6606,\n",
       " 'oprah': 901,\n",
       " 'winfrey': 902,\n",
       " 'jean': 903,\n",
       " 'michel': 904,\n",
       " 'basquiat': 905,\n",
       " 'inspires': 906,\n",
       " 'because': 124,\n",
       " 'lyrical': 11181,\n",
       " 'raw': 2657,\n",
       " 'allfemale': 910,\n",
       " 'background': 1659,\n",
       " 'mamas': 912,\n",
       " '3': 337,\n",
       " 'musicians': 2908,\n",
       " 'introduce': 8890,\n",
       " 'suga': 916,\n",
       " 'mama': 917,\n",
       " 'share': 1147,\n",
       " 'supports': 6569,\n",
       " 'backup': 920,\n",
       " 'characteristics': 2224,\n",
       " 'acclaim': 922,\n",
       " 'former': 813,\n",
       " 'def': 924,\n",
       " 'jam': 12793,\n",
       " 'greatest': 1296,\n",
       " 'alive': 1962,\n",
       " 'praise': 5630,\n",
       " 'chose': 3083,\n",
       " 'dancers': 3743,\n",
       " 'la': 8299,\n",
       " 'reid': 932,\n",
       " 'alice': 933,\n",
       " 'jones': 934,\n",
       " 'singerdancers': 935,\n",
       " 'self': 3269,\n",
       " 'proclaimed': 9457,\n",
       " 'according': 952,\n",
       " 'away': 207,\n",
       " 'back': 107,\n",
       " 'created': 1355,\n",
       " 'no': 67,\n",
       " 'longer': 509,\n",
       " 'needed': 525,\n",
       " 'sex': 1367,\n",
       " 'appeal': 1961,\n",
       " 'characterized': 4819,\n",
       " 'journalist': 8559,\n",
       " 'crossover': 949,\n",
       " 'symbol': 2105,\n",
       " 'word': 373,\n",
       " 'spawned': 952,\n",
       " 'bootylicious': 953,\n",
       " 'oxford': 954,\n",
       " 'dictionary': 2093,\n",
       " '2000s': 956,\n",
       " 'often': 285,\n",
       " 'physical': 791,\n",
       " 'shape': 1311,\n",
       " 'slang': 960,\n",
       " 'been': 48,\n",
       " 'put': 221,\n",
       " 'likes': 5360,\n",
       " 'dress': 1661,\n",
       " 'offstage': 965,\n",
       " 'september': 966,\n",
       " 'area': 307,\n",
       " 'exploring': 14840,\n",
       " 'modelling': 969,\n",
       " 'worlds': 14495,\n",
       " 'gq': 971,\n",
       " 'feature': 3121,\n",
       " 'tv': 973,\n",
       " 'sexiest': 974,\n",
       " 'hottest': 975,\n",
       " 'vh1': 976,\n",
       " 'tom': 977,\n",
       " 'ford': 978,\n",
       " 'complex': 1215,\n",
       " 'museum': 6003,\n",
       " 'models': 2446,\n",
       " 'wax': 6558,\n",
       " 'parent': 6489,\n",
       " 'help': 329,\n",
       " 'cowrite': 985,\n",
       " 'africanamerican': 986,\n",
       " 'posed': 11513,\n",
       " 'si': 988,\n",
       " 'swimsuit': 989,\n",
       " 'mothers': 4222,\n",
       " 'sports': 2482,\n",
       " 'illustrated': 3275,\n",
       " 'bestdressed': 993,\n",
       " 'fan': 5783,\n",
       " 'base': 1307,\n",
       " 'referred': 2499,\n",
       " 'bey': 997,\n",
       " 'hive': 998,\n",
       " 'fans': 4959,\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang.word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lang.word2count, key=lang.word2count.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r, in dev_test.iterrows():\n",
    "    text = r['question_token']\n",
    "    if text != None and text != '':\n",
    "        text = [i for i in text if i]\n",
    "        for t in text:\n",
    "            lang.addWord(t)\n",
    "\n",
    "for i,r, in dev_test.iterrows():\n",
    "    text = r['answer_token']\n",
    "    if text != None and text != '':\n",
    "        text = [i for i in text if i]\n",
    "        for t in text:\n",
    "            lang.addWord(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\n",
    "  'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentencelist):\n",
    "    if sentencelist != None and sentencelist != '':\n",
    "        sentencelist = [i for i in sentencelist if i]\n",
    "        if len(sentencelist) > 0:\n",
    "            return [lang.word2index[word] for word in sentencelist]\n",
    "    return [];\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "        indexes = indexesFromSentence(lang, sentence)\n",
    "        indexes.append(EOS_token)\n",
    "        #indexes.insert(0, SOS_token)\n",
    "        return torch.tensor(indexes, dtype=torch.long, device= device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = [tensorFromSentence(lang, sentencelist) for sentencelist in df_train['question_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = [tensorFromSentence(lang, sentencelist) for sentencelist in df_train['answer_token']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_source_data = [tensorFromSentence(lang, sentencelist) for sentencelist in dev_test['question_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_target_data = [tensorFromSentence(lang, sentencelist) for sentencelist in dev_test['answer_token']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = source_data[0:5000]\n",
    "target_list = target_data[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(list_a, chunk_size):\n",
    "    for i in range(0, len(list_a), chunk_size):\n",
    "        yield list_a[i:i + chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_target_data = dev_target_data[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_source_data = dev_source_data[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "testabc = target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testabc[0][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = testabc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = src.view(  1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    7,     0,   564,  4329, 55001]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['source_data'] = [tensorFromSentence(lang, sentencelist) for sentencelist in df_train['question_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['target_data'] = [tensorFromSentence(lang, sentencelist) for sentencelist in df_train['answer_token']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_test['source_data'] = [tensorFromSentence(lang, sentencelist) for sentencelist in dev_test['question_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_test['target_data'] = [tensorFromSentence(lang, sentencelist) for sentencelist in dev_test['answer_token']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = df_train\n",
    "#columns = ['question', 'answers']\n",
    "#train_data.drop(columns, inplace=True, axis=1)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.reset_option('max_columns')\n",
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_data = dev_test\n",
    "#columns = ['question', 'answers']\n",
    "#valid_data.drop(columns, inplace=True, axis=1)\n",
    "#valid_data.head()\n",
    "#valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def chunker(seq, size):\n",
    "#    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in chunker(train_data[['source_data', 'target_data']].head(10),2):\n",
    "#    print(i['target_data'])\n",
    "#a = train_data['target_data'].head(1)\n",
    "#a[0].shape[0]\n",
    "#a[0][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "oQLTP2Wmi1eB"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hid_dim, n_layers, dropout):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # self.embedding provides a vector representation of the inputs to our model\n",
    "        \n",
    "        # self.lstm, accepts the vectorized input and passes a hidden state\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_dim, self.hid_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.hid_dim, self.hid_dim, n_layers) #, dropout = dropout\n",
    "        \n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    #,  \n",
    "    def forward(self, src, hidden, cell_state):\n",
    "        \n",
    "        '''\n",
    "        Inputs: i, the src vector\n",
    "        Outputs: o, the encoder outputs\n",
    "                h, the hidden state\n",
    "                c, the cell state\n",
    "        '''\n",
    "        \n",
    "        #embedded = self.dropout(self.embedding(src))\n",
    "        embedded = self.embedding(src)\n",
    "        embedded = embedded.view(1, 1, -1)\n",
    "        outputs, (hidden, cell) = self.rnn(embedded, (hidden, cell_state))\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return outputs, hidden, cell\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "      \n",
    "    def __init__(self,  output_dim, hid_dim, n_layers, dropout):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # self.embedding provides a vector representation of the target to our model\n",
    "        \n",
    "        # self.lstm, accepts the embeddings and outputs a hidden state\n",
    "\n",
    "        # self.ouput, predicts on the hidden state via a linear output layer\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_dim, self.hid_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.hid_dim, self.hid_dim, n_layers) #, dropout = dropout\n",
    "        \n",
    "        self.fc_out = nn.Linear(self.hid_dim, self.output_dim)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, src, hidden, cell):\n",
    "        \n",
    "        '''\n",
    "        Inputs: i, the target vector\n",
    "        Outputs: o, the prediction\n",
    "                h, the hidden state\n",
    "        '''\n",
    "        \n",
    "              \n",
    "        #embedded = self.dropout(self.embedding(input))     \n",
    "        embedded = self.embedding(src) \n",
    "        embedded = embedded.view(1, 1, -1)       \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "                \n",
    "        prediction = self.fc_out(output[0])\n",
    "        \n",
    "        prediction = self.softmax(prediction)\n",
    "   \n",
    "        return prediction, hidden, cell\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, src, trg, src_len, trg_len, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        output = {\n",
    "            'decoder_output':[]\n",
    "        }\n",
    "\n",
    "        encoder_hidden = torch.zeros([1, 1, self.encoder.hid_dim]).to(device) # 1 = number of LSTM layers\n",
    "        cell_state = torch.zeros([1, 1, self.encoder.hid_dim]).to(device)\n",
    "        \n",
    "        for i in range(src_len):\n",
    "            encoder_output, encoder_hidden, cell_state = self.encoder(src[i], encoder_hidden, cell_state)\n",
    "            #hidden, cell = self.encoder(src)\n",
    "        \n",
    "       \n",
    "        #input = trg[0,:]\n",
    "        decoder_input = torch.Tensor([[55000]]).long().to(device) # 0 = SOS_token\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        for t in range(trg_len):\n",
    "            decoder_output, decoder_hidden, cell_state  = self.decoder(decoder_input, decoder_hidden, cell_state)\n",
    "            output['decoder_output'].append(decoder_output)\n",
    "            \n",
    "            if self.training: # Model not in eval mode\n",
    "                decoder_input = target_tensor[i] if random.random() > teacher_forcing_ratio else decoder_output.argmax(1) # teacher forcing\n",
    "            else:\n",
    "                _, top_index = decoder_output.data.topk(1)\n",
    "                decoder_input = top_index.squeeze().detach()\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5855\n",
      "5855\n",
      "4432\n",
      "4432\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM =  len(Questionlang.word2index) #len(SRC.vocab)\n",
    "print(INPUT_DIM)\n",
    "print(Questionlang.n_words)\n",
    "OUTPUT_DIM = len(Answerlang.word2index) #len(TRG.vocab)\n",
    "print(OUTPUT_DIM)\n",
    "print(Answerlang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM =  len(Questionlang.word2index) #len(SRC.vocab)\n",
    "OUTPUT_DIM = len(Answerlang.word2index) #len(TRG.vocab)\n",
    "\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "modelSeq2Seq = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def init_weights(m):\n",
    "#    for name, param in m.named_parameters():\n",
    "#        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "#modelSeq2Seq.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def count_parameters(model):\n",
    "#    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "#print(f'The model has {count_parameters(modelSeq2Seq):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(modelSeq2Seq.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    " #ignore_index = TRG_PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train(model, source_data, target_data, optimizer, criterion, epochs, print_every, batch_size):\n",
    "    \n",
    "    model.to(device)\n",
    "    best_valid_loss = float('inf')\n",
    "    total_training_loss = 0\n",
    "    total_valid_loss = 0\n",
    "    loss = 0\n",
    "    \n",
    "    kf = KFold(n_splits=epochs, shuffle=True)\n",
    "    for e, (train_index, test_index) in enumerate(kf.split(source_data), 1):\n",
    "        model.train()\n",
    "        \n",
    "        for i in range(0, len(train_index)):\n",
    "            src = source_data[i]\n",
    "            trg = target_data[i]\n",
    "            \n",
    "            output = model(src, trg, src.size(0), trg.size(0))\n",
    "        \n",
    "        current_loss = 0\n",
    "        for (s, t) in zip(output[\"decoder_output\"], trg): \n",
    "                current_loss += criterion(s, t)\n",
    "\n",
    "        loss += current_loss\n",
    "        total_training_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
    "        \n",
    "        if i % batch_size == 0 or i == (len(train_index)-1):\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    for i in range(0, len(test_index)):\n",
    "        src = source_data[i]\n",
    "        trg = target_data[i]\n",
    "\n",
    "        output = model(src, trg, src.size(0), trg.size(0))\n",
    "\n",
    "        current_loss = 0\n",
    "        for (s, t) in zip(output[\"decoder_output\"], trg): \n",
    "            current_loss += criterion(s, t)\n",
    "            total_valid_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
    "    \n",
    "    if e % print_every == 0:\n",
    "            training_loss_average = total_training_loss / (len(train_index)*print_every)\n",
    "            validation_loss_average = total_valid_loss / (len(test_index)*print_every)\n",
    "            print(\"{}/{} Epoch  -  Training Loss = {:.4f}  -  Validation Loss = {:.4f}\".format(e, epochs, training_loss_average, validation_loss_average))\n",
    "            total_training_loss = 0\n",
    "            total_valid_loss = 0 \n",
    "            \n",
    "    if validation_loss_average < best_valid_loss:\n",
    "        best_valid_loss = validation_loss_average\n",
    "        torch.save(model.state_dict(), 'chatbot-model.pt')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (2, 1, 512), got [1, 1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-624b3f7700c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprint_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       batch_size = 128)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-97bc37855eb9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, source_data, target_data, optimizer, criterion, epochs, print_every, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-a237cd55acb5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, src_len, trg_len, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;31m#hidden, cell = self.encoder(src)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-a237cd55acb5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, hidden, cell_state)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#outputs are always from the top hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0;32m--> 686\u001b[0;31m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    687\u001b[0m         self.check_hidden_size(hidden[1], self.get_expected_cell_size(input, batch_sizes),\n\u001b[1;32m    688\u001b[0m                                'Expected hidden[1] size {}, got {}')\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    224\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 1, 512), got [1, 1, 512]"
     ]
    }
   ],
   "source": [
    "train(model = modelSeq2Seq,\n",
    "      source_data = source_list,\n",
    "      target_data = target_list,\n",
    "      optimizer = optimizer,\n",
    "      criterion = criterion,\n",
    "      epochs = 65,\n",
    "      print_every = 5,\n",
    "      batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
